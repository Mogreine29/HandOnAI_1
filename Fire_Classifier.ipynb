{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandOnAI_1/blob/main/Fire_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/api/applications/\n",
        "\n",
        "|Model|Size (MB)|\tTop-1 Accuracy|\tParameters|\tDepth|\tTime (ms) inference (GPU)|\n",
        "|---|---|---|---|---|---|\n",
        "|MobileNet|\t16|\t70.4%|4.3M|\t55\t|\t3.4|\n",
        "|Xception|\t88|\t79%\t|22.9M|\t81|\t\t8.1|\n",
        "|InceptionResNetV2|\t215\t|80.3%|\t55.9M|\t449|\t\t10.0|\n",
        "|EfficientNetB6|\t166|\t84.0%\t|43.3M|\t360\t|40.4|"
      ],
      "metadata": {
        "id": "_VKrBQLx5GJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDVclcqMqfd1"
      },
      "outputs": [],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-explain"
      ],
      "metadata": {
        "id": "7O1ONz7EDv8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "\n",
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "\n",
        "# For Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "\n",
        "from keras.applications.densenet import DenseNet121\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Data augmentation \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Tensorflow Explicability\n",
        "import tf_explain\n",
        "%load_ext tensorboard\n",
        "\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ],
      "metadata": {
        "id": "CSivVPy1Dm4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "drive_data_folder = '/content/gdrive/MyDrive/HandOnAI_1_Fire/'"
      ],
      "metadata": {
        "id": "3fC5i31aPypa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_images( s_dir, ext_list):\n",
        "    bad_images=[]\n",
        "    bad_ext=[]\n",
        "    s_list= os.listdir(s_dir)\n",
        "    for klass in s_list:\n",
        "        klass_path=os.path.join (s_dir, klass)\n",
        "        print ('processing class directory ', klass)\n",
        "        if os.path.isdir(klass_path):\n",
        "            file_list=os.listdir(klass_path)\n",
        "            for f in file_list:               \n",
        "                f_path=os.path.join (klass_path,f)\n",
        "                tip = imghdr.what(f_path)\n",
        "                if ext_list.count(tip) == 0:\n",
        "                  bad_images.append(f_path)\n",
        "                if os.path.isfile(f_path):\n",
        "                    try:\n",
        "                        img=cv2.imread(f_path)\n",
        "                        shape=img.shape\n",
        "                    except:\n",
        "                        print('file ', f_path, ' is not a valid image file')\n",
        "                        bad_images.append(f_path)\n",
        "                else:\n",
        "                    print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
        "        else:\n",
        "            print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
        "    return bad_images, bad_ext\n",
        "\n",
        "source_dir =r'/content/gdrive/MyDrive/HandOnAI_1_Fire/'\n",
        "good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions\n",
        "bad_file_list, bad_ext_list=check_images(source_dir, good_exts)\n",
        "if len(bad_file_list) !=0:\n",
        "    print('improper image files are listed below')\n",
        "    for i in range (len(bad_file_list)):\n",
        "        print (bad_file_list[i])\n",
        "        os.remove(bad_file_list[i])\n",
        "else:\n",
        "    print(' no improper image files were found')"
      ],
      "metadata": {
        "id": "MvA3Xauo0u7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!printf '%s\\n' 'fire' 'no_fire' 'start_fire'> classes.txt"
      ],
      "metadata": {
        "id": "R4XIkW3iECpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = dict(\n",
        "      nb_classes = 3,                         # fire, no_fire, start_fire\n",
        "      batch_size = 64,                         # computed images before backpropagation\n",
        "      input_dim = 224,                        # size of the input depending of the backbone\n",
        "      epochs = 15,                             \n",
        "      dataset_name = drive_data_folder,       # dataset loaded from google.drive\n",
        "      classifier = \"Xception\",                # select the backbone\n",
        "      pretrain_weights = 'imagenet',\n",
        "      init_learning_rate = 0.001,\n",
        "      lr_decay_rate = 0.1,\n",
        "      optimizer = 'adam',                      # SGD, Adam, RMSprop\n",
        "      loss_fn = 'categorical_crossentropy',   \n",
        "      metrics = ['acc'],\n",
        "      earlystopping_patience = 5,\n",
        "      seed = 42,\n",
        "      validation_split = 0.2\n",
        "    )\n",
        "\n",
        "tf.keras.utils.set_random_seed(configs['seed']) # Fixe seed to get more stable results\n",
        "\n",
        "classes_path = 'classes.txt'\n",
        "csv_path = 'result.csv'\n",
        "#dataset_path = 'bases'\n",
        "result_path = 'results/' + configs['classifier']\n",
        "#dataset_path = os.path.join('bases/', configs['dataset_name'])\n",
        "result_path='results/'\n",
        "log_path='logs'\n",
        "result_path = 'results/' + configs['classifier']"
      ],
      "metadata": {
        "id": "hqhcZPa8EE8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(f'Classes : {classes}')\n",
        "print(f'Number of classes : {num_classes}')"
      ],
      "metadata": {
        "id": "-ZebFuE9EFDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tconfigs['dataset_name'],          \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # Path of the dataset\n",
        "\tvalidation_split = configs['validation_split'],             \t\t\t\t\t\t# Data division : validation (20%), train (80%)\n",
        "\tsubset = 'training',                \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Selection of training data\n",
        "\tseed = configs['seed'],                          \t\t\t\t\t\t\t\t\t\t\t\t# Initialization of random generator (for permutations)\n",
        "\timage_size = (configs['input_dim'], configs['input_dim']),    \t\t\t\t\t# Input size of images\n",
        "\tbatch_size = configs['batch_size'],\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch_size\n",
        "  label_mode = 'categorical'     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Conversion to One-Hot format\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tconfigs['dataset_name'],          \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # Path of the dataset\n",
        "\tvalidation_split = configs['validation_split'],             \t\t\t\t\t\t# Data division : validation (20%), train (80%)\n",
        "\tsubset = 'validation',              \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Selection of validation data\n",
        "\tseed = configs['seed'],                         \t\t\t\t\t\t\t\t\t\t\t\t# Initialization of random generator (for permutations)\n",
        "\timage_size = (configs['input_dim'], configs['input_dim']),    \t\t\t\t\t# Input size of images\n",
        "\tbatch_size = configs['batch_size'], \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch_size\n",
        "  label_mode = 'categorical'     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Conversion to One-Hot format\n",
        ")"
      ],
      "metadata": {
        "id": "FMtdSwtZEFFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen_args = dict(preprocessing_function=preprocess_input,\n",
        "                                   horizontal_flip=False,\n",
        "                                   rotation_range = 10,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   height_shift_range = 0.1,\n",
        "                                   validation_split = 0.2\n",
        "                                   )\n",
        "\n",
        "color_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "train_color_generator = color_datagen.flow_from_directory(\n",
        "  configs['dataset_name'],          \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # Path of the dataset             \t\t\t\n",
        "\tsubset = 'training',                \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Selection of training data\n",
        "\tseed = configs['seed'],                          \t\t\t\t\t\t\t\t\t\t\t\t# Initialization of random generator (for permutations)\n",
        "\ttarget_size = (configs['input_dim'], configs['input_dim']),    \t\t\t\t\t# Input size of images\n",
        "\tbatch_size = configs['batch_size'], \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch_size\n",
        "  class_mode = 'categorical'\n",
        "  )"
      ],
      "metadata": {
        "id": "kp3pUrvKEvLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(32):\n",
        "        ax = plt.subplot(6, 6, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "p2tNphpyhRZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "images, _ = next(train_color_generator)\n",
        "\n",
        "for i in range(32):\n",
        "    ax = plt.subplot(6, 6, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "8d5KqVawHb32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "images, _ = next(train_bw_generator)\n",
        "\n",
        "for i in range(32):\n",
        "    ax = plt.subplot(6, 6, i + 1)\n",
        "    plt.imshow(images[i][:,:,0])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "jdrL9VfbKr_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import  Sequence\n",
        "\n",
        "class MergedGenerators(Sequence):\n",
        "    def __init__(self, *generators):\n",
        "        self.generators = generators\n",
        "        # TODO add a check to verify that all generators have the same length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.generators[0])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return [generator[index] for generator in self.generators]\n",
        "\n",
        "train_merged_generator = MergedGenerators(train_generator_no_aug, train_bw_generator, train_color_generator)"
      ],
      "metadata": {
        "id": "krzLu9J_MVjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged_generator.__getitem__"
      ],
      "metadata": {
        "id": "oYUAw4M9n-Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://195.154.53.219/downloads/test.tar\n",
        "!tar xf test.tar --one-top-level\n",
        "!rm test.tar"
      ],
      "metadata": {
        "id": "IPZ0eQe8fCo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\t\"/content/test/\",          \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # Path of the dataset                         \t\t\t\t\t\t\t\t\t\t\t\t# Initialization of random generator (for permutations)\n",
        "\timage_size = (configs['input_dim'], configs['input_dim']),    \t\t\t\t\t# Input size of images\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch_size\n",
        "  label_mode = 'categorical'     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Conversion to One-Hot format\n",
        ")"
      ],
      "metadata": {
        "id": "kj7UIBcmfazp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "  base_model = Xception(\n",
        "      include_top = False, \n",
        "      weights ='imagenet', \n",
        "      input_shape = (configs['input_dim'], configs['input_dim'],3))\n",
        "\n",
        "  model = base_model.output\n",
        "  model = Flatten()(model)\n",
        "  model = Dense(128, activation='relu')(model)\n",
        "  model = Dropout(0.4)(model)\n",
        "  model = Dense(32, activation = 'relu',  name=\"layer2\")(model)\n",
        "  model = Dropout(0.4)(model)\n",
        "  predictions = Dense(3, activation = 'softmax')(model)\n",
        "\n",
        "  model = Model(inputs=base_model.inputs, outputs = predictions)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "AecWFRAjEFHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "#model.summary()\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file = 'model_summary.png',\n",
        "    show_shapes = True,                 # show size of the layer\n",
        "    show_dtype = False,                        \n",
        "    show_layer_names = True,\n",
        "    rankdir = 'TB',                     # TB : vertical ; LR : horizontal\n",
        "    expand_nested = False,\n",
        "    dpi = 70,                           # size of the graph\n",
        "    layer_range = None,                 # pass a list of the first and the last layer to draw\n",
        "    show_layer_activations = True       # show activation function type\n",
        ")"
      ],
      "metadata": {
        "id": "sqdTQWbAoC6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config: dict, callbacks: list, verbose: int=0):\n",
        "  \n",
        "  tf.keras.backend.clear_session()                  # https://stackoverflow.com/questions/57731214/what-tf-keras-backend-clear-session-actually-do\n",
        "  \n",
        "  model = build_model()\n",
        "\n",
        "  # Select layers to be trained\n",
        "  for layer in model.layers:\n",
        "      layer.trainable = False                       # Freeze all the model\n",
        "  \n",
        "  for layer in model.layers[:-6]:\n",
        "      layer.trainable = True\n",
        "\n",
        "\n",
        "  # recompiler le modèle\n",
        "  opt = keras.optimizers.SGD(learning_rate=config['init_learning_rate'])\n",
        "  opt2 = keras.optimizers.Adam(learning_rate=config['init_learning_rate'])\n",
        "  opt3 = keras.optimizers.RMSprop(learning_rate=config['init_learning_rate'])\n",
        "\n",
        "  model.compile(loss=config['loss_fn'],optimizer=opt2,metrics=config['metrics'])  \n",
        "\n",
        "\n",
        "  # Création du dossier pour sauvegrader le model\n",
        "  if os.path.exists(result_path) == False:\n",
        "      os.makedirs(result_path)\n",
        "\n",
        "  # keras_callback = [EarlyStopping(monitor='val_loss',patience = config['earlystopping_patience'], mode='auto',restore_best_weights=True)]\n",
        "  history = model.fit_generator(\n",
        "      train_color_generator,\n",
        "      steps_per_epoch=math.ceil(len(train_ds)),\n",
        "      epochs=config['epochs'],\n",
        "      validation_data = val_ds,\n",
        "      validation_steps=math.ceil(len(val_ds)),\n",
        "      #callbacks = callbacks\n",
        "  )\n",
        "  return model, history"
      ],
      "metadata": {
        "id": "y15R8UXHEvb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/', histogram_freq=1)"
      ],
      "metadata": {
        "id": "Cjb6UHDiFA_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [tensorboard_callback]\n",
        "\n",
        "# Train\n",
        "!rm -rf logs\n",
        "model, history = train(configs, callbacks, 1)\n",
        "\n",
        "# Evaluate the trained model\n",
        "loss, acc = model.evaluate(val_ds)\n",
        "\n",
        "print(\"validation : \", loss, acc)\n",
        "      \n",
        "# Evaluate the trained model\n",
        "loss, acc = model.evaluate(test_ds)  \n",
        "\n",
        "print(\"test : \", loss, acc)"
      ],
      "metadata": {
        "id": "IRvhcIe_E5v4",
        "outputId": "e2dcaca2-532a-4f09-d1ae-4af50bfd7275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "11/24 [============>.................] - ETA: 12:03 - loss: 0.9828 - acc: 0.5383"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12 bytes but only got 10. Skipping tag 42037\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Xception_64_15.h5')"
      ],
      "metadata": {
        "id": "hAHHhbvSEveB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload();"
      ],
      "metadata": {
        "id": "dKltG6FYEvgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "image_path = \"fog.jpg\"\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "x = tf.keras.utils.img_to_array(img,data_format='channels_last')\n",
        "x = tf.keras.preprocessing.image.smart_resize(x, size=(224,224))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# predict\n",
        "pred = model.predict(x,batch_size=1)[0]\n",
        "\n",
        "for (pos,prob) in enumerate(pred):\n",
        "    class_name = classes[pos]\n",
        "    if (pos == np.argmax(pred)) :\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX \n",
        "        textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "        textX = (img.shape[1] - textsize[0]) / 2\n",
        "        textY = (img.shape[0] + textsize[1]) / 2\n",
        "        cv2.putText(img, class_name, (int(textX)-10, int(textY)), font, 2, (255,0,0), 6, cv2.LINE_AA)\n",
        "        plt.imshow(img)\n",
        "    print(\"Class Name : %s\" % (class_name), \"---\", \"Class Probability: %.2f%%\" % (prob*100))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xv4Pa4e3Evh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "AxfOMt7XFJDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}