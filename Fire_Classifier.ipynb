{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMIa0QBtsm+2ewOYlxKH1L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinCord/HandOnAI_1/blob/main/Fire_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/api/applications/\n",
        "\n",
        "|Model|Size (MB)|\tTop-1 Accuracy|\tParameters|\tDepth|\tTime (ms) inference (GPU)|\n",
        "|---|---|---|---|---|---|\n",
        "|MobileNet|\t16|\t70.4%|4.3M|\t55\t|\t3.4|\n",
        "|Xception|\t88|\t79%\t|22.9M|\t81|\t\t8.1|\n",
        "|InceptionResNetV2|\t215\t|80.3%|\t55.9M|\t449|\t\t10.0|\n",
        "|EfficientNetB6|\t166|\t84.0%\t|43.3M|\t360\t|40.4|"
      ],
      "metadata": {
        "id": "_VKrBQLx5GJL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDVclcqMqfd1"
      },
      "outputs": [],
      "source": [
        "!/opt/bin/nvidia-smi\n",
        "!rm -rf sample_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-explain"
      ],
      "metadata": {
        "id": "7O1ONz7EDv8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import math\n",
        "import argparse\n",
        "import matplotlib\n",
        "import imghdr\n",
        "import pickle as pkl\n",
        "import datetime\n",
        "\n",
        "from IPython.display import Image, HTML, display\n",
        "from matplotlib import pyplot as plt\n",
        "from cycler import cycler\n",
        "from PIL import Image, ImageEnhance\n",
        "from google.colab import files\n",
        "\n",
        "# For Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input #224*224\n",
        "from keras.applications.xception import Xception, preprocess_input, decode_predictions #299*299\n",
        "from keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions #224*224\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Flatten, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Tensorflow Explicability\n",
        "import tf_explain\n",
        "%load_ext tensorboard\n",
        "\n",
        "print(\"Tensorflow version: \"+tf.__version__)\n",
        "print(\"Keras version: \" + tf.keras.__version__)"
      ],
      "metadata": {
        "id": "CSivVPy1Dm4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "drive_data_folder = '/content/gdrive/MyDrive/HandOnAI_1_Fire/'"
      ],
      "metadata": {
        "id": "1Ogerf-ZD46l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!printf '%s\\n' 'fire' 'no_fire' 'start_fire'> classes.txt"
      ],
      "metadata": {
        "id": "R4XIkW3iECpA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "configs = dict(\n",
        "      nb_classes = 3,                         # fire, no_fire, start_fire\n",
        "      batch_size = 8,                         # computed images before backpropagation\n",
        "      input_dim = 224,                        # size of the input depending of the backbone\n",
        "      epochs = 1,                             \n",
        "      dataset_name = drive_data_folder,       # dataset loaded from google.drive\n",
        "      classifier = \"Xception\",                # select the backbone\n",
        "      pretrain_weights = 'imagenet',\n",
        "      init_learning_rate = 0.001,\n",
        "      lr_decay_rate = 0.1,\n",
        "      optimizer = 'adam',                      # SGD, Adam, RMSprop\n",
        "      loss_fn = 'categorical_crossentropy',   \n",
        "      metrics = ['acc'],\n",
        "      earlystopping_patience = 5,\n",
        "      seed = 42\n",
        "      validation_split = 0.2\n",
        "    )\n",
        "\n",
        "tf.keras.utils.set_random_seed(configs['seed']) # Fixe seed to get more stable results\n",
        "\n",
        "classes_path = 'classes.txt'\n",
        "csv_path = 'result.csv'\n",
        "#dataset_path = 'bases'\n",
        "result_path = 'results/' + configs['classifier']\n",
        "#dataset_path = os.path.join('bases/', configs['dataset_name'])\n",
        "result_path='results/'\n",
        "log_path='logs'\n",
        "result_path = 'results/' + configs['classifier']"
      ],
      "metadata": {
        "id": "hqhcZPa8EE8y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(classes_path, 'r') as f:\n",
        "    classes = f.readlines()\n",
        "    classes = list(map(lambda x: x.strip(), classes))\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(f'Classes : {classes}')\n",
        "print(f'Number of classes : {num_classes}')"
      ],
      "metadata": {
        "id": "-ZebFuE9EFDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tconfigs['dataset_name'],          \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # Path of the dataset\n",
        "\tvalidation_split = configs['validation_split'],             \t\t\t\t\t\t# Data division : validation (20%), train (80%)\n",
        "\tsubset = 'training',                \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Selection of training data\n",
        "\tseed = configs['seed'],                          \t\t\t\t\t\t\t\t\t\t\t\t# Initialization of random generator (for permutations)\n",
        "\timage_size = (configs['input_dim'], configs['input_dim']),    \t\t\t\t\t# Input size of images\n",
        "\tbatch_size = configs['batch_size'],\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch_size\n",
        "  label_mode = 'categorical'     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Conversion to One-Hot format\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tconfigs['dataset_name'],          \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  # Path of the dataset\n",
        "\tvalidation_split = configs['validation_split'],             \t\t\t\t\t\t# Data division : validation (20%), train (80%)\n",
        "\tsubset = 'validation',              \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Selection of validation data\n",
        "\tseed = configs['seed'],                         \t\t\t\t\t\t\t\t\t\t\t\t# Initialization of random generator (for permutations)\n",
        "\timage_size = (configs['input_dim'], configs['input_dim']),    \t\t\t\t\t# Input size of images\n",
        "\tbatch_size = configs['batch_size'], \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Batch_size\n",
        "  label_mode = 'categorical'     \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Conversion to One-Hot format\n",
        ")"
      ],
      "metadata": {
        "id": "FMtdSwtZEFFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "\n",
        "  base_model = Xception(\n",
        "      include_top = False, \n",
        "      weights ='imagenet', \n",
        "      input_shape = (configs['input_dim'], configs['input_dim'],3))\n",
        "\n",
        "  model = base_model.output\n",
        "  model = Flatten()(model)\n",
        "  model = Dense(128, activation='relu')(model)\n",
        "  model = Dropout(0.8)(model)\n",
        "  model = Dense(64, activation = 'relu',  name=\"layer2\")(model)\n",
        "  model = Dropout(0.4)(model)\n",
        "  \n",
        "  predictions = Dense(3, activation = 'softmax')(model)\n",
        "\n",
        "  model = Model(inputs=base_model.inputs, outputs = predictions)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "AecWFRAjEFHb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "#model.summary()\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file = 'model_summary.png',\n",
        "    show_shapes = True,                 # show size of the layer\n",
        "    show_dtype = False,                        \n",
        "    show_layer_names = True,\n",
        "    rankdir = 'TB',                     # TB : vertical ; LR : horizontal\n",
        "    expand_nested = False,\n",
        "    dpi = 70,                           # size of the graph\n",
        "    layer_range = None,                 # pass a list of the first and the last layer to draw\n",
        "    show_layer_activations = True       # show activation function type\n",
        ")"
      ],
      "metadata": {
        "id": "sqdTQWbAoC6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config: dict, callbacks: list, verbose: int=0):\n",
        "  \n",
        "  tf.keras.backend.clear_session()                  # https://stackoverflow.com/questions/57731214/what-tf-keras-backend-clear-session-actually-do\n",
        "  \n",
        "  model = build_model()\n",
        "\n",
        "  # Select layers to be trained\n",
        "  for layer in model.layers:\n",
        "      layer.trainable = False                       # Freeze all the model\n",
        "  \n",
        "  for layer in model.layers[:-5]:\n",
        "      layer.trainable = True\n",
        "\n",
        "\n",
        "  # recompiler le modèle\n",
        "  opt = keras.optimizers.SGD(learning_rate=config['init_learning_rate'])\n",
        "  opt2 = keras.optimizers.Adam(learning_rate=config['init_learning_rate'])\n",
        "  opt3 = keras.optimizers.RMSprop(learning_rate=config['init_learning_rate'])\n",
        "\n",
        "  model.compile(loss=config['loss_fn'],optimizer=opt2,metrics=config['metrics'])  \n",
        "\n",
        "\n",
        "  # Création du dossier pour sauvegrader le model\n",
        "  if os.path.exists(result_path) == False:\n",
        "      os.makedirs(result_path)\n",
        "\n",
        "  # keras_callback = [EarlyStopping(monitor='val_loss',patience = config['earlystopping_patience'], mode='auto',restore_best_weights=True)]\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      steps_per_epoch=math.ceil(len(train_ds)),\n",
        "      epochs=config['epochs'],\n",
        "      validation_data=val_ds,\n",
        "      validation_steps=math.ceil(len(val_ds)),\n",
        "      callbacks = callbacks\n",
        "  )\n",
        "  return model, history"
      ],
      "metadata": {
        "id": "y15R8UXHEvb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs/', histogram_freq=1)"
      ],
      "metadata": {
        "id": "Cjb6UHDiFA_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [tensorboard_callback]\n",
        "\n",
        "# Train\n",
        "!rm -rf logs\n",
        "model, history = train(configs, callbacks, 1)\n",
        "\n",
        "# Evaluate the trained model\n",
        "loss, acc = model.evaluate(val_ds)"
      ],
      "metadata": {
        "id": "IRvhcIe_E5v4",
        "outputId": "c9c2458a-184a-4067-f7cc-0cd33f0d67eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n",
            "168/168 [==============================] - 1503s 9s/step - loss: 1.1235 - acc: 0.4664 - val_loss: 1.7284 - val_acc: 0.5569\n",
            "42/42 [==============================] - 69s 2s/step - loss: 1.7284 - acc: 0.5569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('test.h5')"
      ],
      "metadata": {
        "id": "hAHHhbvSEveB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload();"
      ],
      "metadata": {
        "id": "dKltG6FYEvgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "image_path = \"fog.jpg\"\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "x = tf.keras.utils.img_to_array(img,data_format='channels_last')\n",
        "x = tf.keras.preprocessing.image.smart_resize(x, size=(224,224))\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# predict\n",
        "pred = model.predict(x,batch_size=1)[0]\n",
        "\n",
        "for (pos,prob) in enumerate(pred):\n",
        "    class_name = classes[pos]\n",
        "    if (pos == np.argmax(pred)) :\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        font = cv2.FONT_HERSHEY_COMPLEX \n",
        "        textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "        textX = (img.shape[1] - textsize[0]) / 2\n",
        "        textY = (img.shape[0] + textsize[1]) / 2\n",
        "        cv2.putText(img, class_name, (int(textX)-10, int(textY)), font, 2, (255,0,0), 6, cv2.LINE_AA)\n",
        "        plt.imshow(img)\n",
        "    print(\"Class Name : %s\" % (class_name), \"---\", \"Class Probability: %.2f%%\" % (prob*100))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xv4Pa4e3Evh7",
        "outputId": "f97f6138-7392-418e-c471-b42895208490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-30dcaedb74d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fog.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fog.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "AxfOMt7XFJDd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}